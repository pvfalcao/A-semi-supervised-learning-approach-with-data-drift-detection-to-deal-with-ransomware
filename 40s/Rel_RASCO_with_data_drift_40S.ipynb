{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NeIjs9yKHdLidWLEYP2goq633qNSISVt",
      "authorship_tag": "ABX9TyP2ben12rcbq2bXY/JOBMnk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pvfalcao/A-semi-supervised-learning-approach-with-data-drift-detection-to-deal-with-ransomware/blob/main/40s/Rel_RASCO_with_data_drift_40S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação de bibliotecas\n"
      ],
      "metadata": {
        "id": "-gm4LuQjklVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sslearn\n",
        "!pip install frouros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXVlby4mLgBP",
        "outputId": "29fba380-b900-46dd-d794-c503bee7a72e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sslearn in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.12/dist-packages (from sslearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.12/dist-packages (from sslearn) (2.2.2)\n",
            "Requirement already satisfied: scikit_learn>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.14.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from sslearn) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>=1.2.0->sslearn) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->sslearn) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->sslearn) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->sslearn) (1.17.0)\n",
            "Requirement already satisfied: frouros in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: matplotlib<3.10,>=3.8.2 in /usr/local/lib/python3.12/dist-packages (from frouros) (3.9.4)\n",
            "Requirement already satisfied: numpy<2.2,>=1.26.3 in /usr/local/lib/python3.12/dist-packages (from frouros) (2.0.2)\n",
            "Requirement already satisfied: requests<2.33,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from frouros) (2.32.4)\n",
            "Requirement already satisfied: scipy<1.15,>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from frouros) (1.14.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from frouros) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<3.10,>=3.8.2->frouros) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch979MWf0McF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sslearn\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sslearn.wrapper import RelRasco\n",
        "from sslearn.model_selection import artificial_ssl_dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from frouros.callbacks.batch import PermutationTestDistanceBased\n",
        "from frouros.detectors.data_drift import MMD\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.manifold import TSNE\n",
        "from frouros.detectors.data_drift import KSTest\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recebendo conjunto de dados\n"
      ],
      "metadata": {
        "id": "2crT30H6kvMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/content/drive/MyDrive/Navarra/N40S40/N40S40.csv', header = None)\n",
        "zero = pd.read_csv(r'/content/drive/MyDrive/Navarra/N40S40/zeroDays.csv', header = None)\n",
        "user = pd.read_csv(r'/content/drive/MyDrive/Navarra/N40S40/userSamples_train.csv', header = None)\n",
        "\n",
        "targets = df.iloc[:,df.shape[1] - 1]\n",
        "df = df.iloc[:,0:-1]\n",
        "tz = zero.iloc[:,zero.shape[1] - 1]\n",
        "zero = zero.iloc[:,0:-1]\n",
        "tu = user.iloc[:,user.shape[1] - 1]\n",
        "user = user.iloc[:,0:-1]\n"
      ],
      "metadata": {
        "id": "yEYN4Nny0Uf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf-QtKbZ_8t1",
        "outputId": "091cfad3-1e96-4e86-d63f-3e0f8b003653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo"
      ],
      "metadata": {
        "id": "-3dGzmId-b0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Initialize the variables\n",
        "\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "# Initialize 10-Fold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "clf = RelRasco()\n",
        "\n",
        "#Consumption metrics\n",
        "\n",
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "\n",
        "  psutil.cpu_percent(interval=None)\n",
        "  start = time.process_time()\n",
        "\n",
        "  # Split the dataset into 10 folds\n",
        "\n",
        "  for fold, (train_idx, test_idx) in enumerate(skf.split(df, targets)):\n",
        "\n",
        "      # Select data using .iloc to get pandas DataFrames/Series\n",
        "      train_features = df.iloc[train_idx]\n",
        "      train_labels = targets.iloc[train_idx]\n",
        "      test_features = df.iloc[test_idx]\n",
        "      test_labels = targets.iloc[test_idx]\n",
        "      TP = 0\n",
        "      FP = 0\n",
        "      TN = 0\n",
        "      FN = 0\n",
        "      counter = 0\n",
        "      precision_list = []\n",
        "      recall_list = []\n",
        "      f1_list = []\n",
        "      accuracy_list = []\n",
        "\n",
        "\n",
        "      X_train, X_test = df.iloc[train_idx], df.iloc[test_idx]\n",
        "      y_train, y_test = targets.iloc[train_idx], targets.iloc[test_idx]\n",
        "\n",
        "      for i in range(X_train.shape[1]):\n",
        "        feature_idx = i\n",
        "        alpha = 0.01\n",
        "        # Define and fit detector\n",
        "        detector = KSTest()\n",
        "\n",
        "        X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        __ = detector.fit(X_train_numeric)\n",
        "            # Convert the feature column to numeric before comparing\n",
        "        X_test_numeric = pd.to_numeric(X_test.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        "        # Check if drift is taking place\n",
        "        if result.p_value <= alpha:\n",
        "            counter += 1\n",
        "        if counter>(X_train.shape[1]/2):\n",
        "          print(\"More than half of features had data drift detected.\")\n",
        "\n",
        "          X_add = X_test.sample(frac=0.2, random_state=42)\n",
        "          y_add = y_test.sample(frac=0.2, random_state=42)\n",
        "          X_train = pd.concat([X_train, X_add])\n",
        "          y_train = pd.concat([y_train, y_add])\n",
        "          X_test = X_test.drop(X_add.index)\n",
        "          y_test = y_test.drop(y_add.index)\n",
        "          print(\"Datasets updated\")\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "      X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "      clf.fit(X_ss, y_ss)\n",
        "\n",
        "        # Unlabeled score\n",
        "      print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      y_pred = clf.predict(X_test)\n",
        "\n",
        "      TN, FP, FN, TP = confusion_matrix(y_pred, y_test).ravel()\n",
        "\n",
        "      precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "      recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "      f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "      accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "\n",
        "\n",
        "      accuracy_list.append(accuracy)\n",
        "      precision_list.append(precision)\n",
        "      recall_list.append(recall)\n",
        "      f1_list.append(f1)\n",
        "\n",
        "\n",
        "\n",
        "  #Consumption measures\n",
        "  end = time.process_time()\n",
        "  print('The processing time was:', end - start)\n",
        "  cpu_usage_system = psutil.cpu_percent(interval=None)\n",
        "  print(f\"System-wide CPU usage: {cpu_usage_system}%\")\n",
        "  print(f\"Load average:{psutil.getloadavg()}\")\n",
        "  print(f\"CPU Frequency:{psutil.cpu_freq()}\")\n",
        "  print(\"CPU usage (%):\", psutil.cpu_percent())\n",
        "  print(\"CPU usage (%):\", psutil.cpu_percent())\n",
        "  ram = psutil.virtual_memory()\n",
        "  print(\"RAM usage (%):\", ram.percent)\n",
        "  print(\"RAM used (GB):\", round(ram.used / 1e9, 2))\n",
        "  mean_precision = sum(precision_list) / len(precision_list)\n",
        "  mean_recall = sum(recall_list) / len(recall_list)\n",
        "  mean_f1 = sum(f1_list) / len(f1_list)\n",
        "  mean_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
        "  print(f'Mean precision: {mean_precision:.5f}')\n",
        "  print(f'Mean recall: {mean_recall:.5f}')\n",
        "  print(f'Mean F1 Score: {mean_f1:.5f}')\n",
        "  print(f'Mean accuracy: {mean_accuracy:.5f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-RG403E0XHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4eda99-570f-4dcf-d9f6-cebdd6c3b10a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR=0.1] Unlabeled score: 0.9953\n",
            "[LR=0.1] Unlabeled score: 0.9930\n",
            "[LR=0.1] Unlabeled score: 0.9945\n",
            "[LR=0.1] Unlabeled score: 0.9934\n",
            "[LR=0.1] Unlabeled score: 0.9958\n",
            "[LR=0.1] Unlabeled score: 0.9941\n",
            "[LR=0.1] Unlabeled score: 0.9950\n",
            "[LR=0.1] Unlabeled score: 0.9950\n",
            "[LR=0.1] Unlabeled score: 0.9963\n",
            "[LR=0.1] Unlabeled score: 0.9937\n",
            "The processing time was: 100.88095304\n",
            "System-wide CPU usage: 66.9%\n",
            "Load average:(1.7119140625, 1.5244140625, 0.71875)\n",
            "CPU Frequency:scpufreq(current=2200.21, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.4\n",
            "RAM used (GB): 1.62\n",
            "Mean precision: 0.98892\n",
            "Mean recall: 0.99443\n",
            "Mean F1 Score: 0.99167\n",
            "Mean accuracy: 0.99604\n",
            "[LR=0.2] Unlabeled score: 0.9970\n",
            "[LR=0.2] Unlabeled score: 0.9964\n",
            "[LR=0.2] Unlabeled score: 0.9967\n",
            "[LR=0.2] Unlabeled score: 0.9982\n",
            "[LR=0.2] Unlabeled score: 0.9973\n",
            "[LR=0.2] Unlabeled score: 0.9975\n",
            "[LR=0.2] Unlabeled score: 0.9970\n",
            "[LR=0.2] Unlabeled score: 0.9962\n",
            "[LR=0.2] Unlabeled score: 0.9975\n",
            "[LR=0.2] Unlabeled score: 0.9973\n",
            "The processing time was: 196.15144487600003\n",
            "System-wide CPU usage: 67.3%\n",
            "Load average:(1.48291015625, 1.5615234375, 0.9052734375)\n",
            "CPU Frequency:scpufreq(current=2200.21, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.1\n",
            "RAM used (GB): 1.58\n",
            "Mean precision: 0.99446\n",
            "Mean recall: 0.99722\n",
            "Mean F1 Score: 0.99584\n",
            "Mean accuracy: 0.99802\n",
            "[LR=0.3] Unlabeled score: 0.9977\n",
            "[LR=0.3] Unlabeled score: 0.9972\n",
            "[LR=0.3] Unlabeled score: 0.9978\n",
            "[LR=0.3] Unlabeled score: 0.9974\n",
            "[LR=0.3] Unlabeled score: 0.9974\n",
            "[LR=0.3] Unlabeled score: 0.9964\n",
            "[LR=0.3] Unlabeled score: 0.9959\n",
            "[LR=0.3] Unlabeled score: 0.9958\n",
            "[LR=0.3] Unlabeled score: 0.9962\n",
            "[LR=0.3] Unlabeled score: 0.9977\n",
            "The processing time was: 310.755249309\n",
            "System-wide CPU usage: 67.5%\n",
            "Load average:(1.45703125, 1.57177734375, 1.10791015625)\n",
            "CPU Frequency:scpufreq(current=2200.21, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.1\n",
            "RAM used (GB): 1.58\n",
            "Mean precision: 0.98892\n",
            "Mean recall: 0.99721\n",
            "Mean F1 Score: 0.99305\n",
            "Mean accuracy: 0.99670\n",
            "[LR=0.4] Unlabeled score: 0.9978\n",
            "[LR=0.4] Unlabeled score: 0.9968\n",
            "[LR=0.4] Unlabeled score: 0.9984\n",
            "[LR=0.4] Unlabeled score: 0.9984\n",
            "[LR=0.4] Unlabeled score: 0.9983\n",
            "[LR=0.4] Unlabeled score: 0.9985\n",
            "[LR=0.4] Unlabeled score: 0.9982\n",
            "[LR=0.4] Unlabeled score: 0.9973\n",
            "[LR=0.4] Unlabeled score: 0.9972\n",
            "[LR=0.4] Unlabeled score: 0.9974\n",
            "The processing time was: 433.04243771200004\n",
            "System-wide CPU usage: 68.3%\n",
            "Load average:(1.90625, 1.68603515625, 1.31640625)\n",
            "CPU Frequency:scpufreq(current=2200.21, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.5\n",
            "RAM used (GB): 1.63\n",
            "Mean precision: 0.99446\n",
            "Mean recall: 0.99722\n",
            "Mean F1 Score: 0.99584\n",
            "Mean accuracy: 0.99802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(X_train.shape[1]):\n",
        " feature_idx = i\n",
        " alpha = 0.01\n",
        " # Define and fit detector\n",
        " detector = KSTest()\n",
        "\n",
        " X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        " __ = detector.fit(X_train_numeric)\n",
        "    # Convert the feature column to numeric before comparing\n",
        " X_test_numeric = pd.to_numeric(X_test.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        " result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        " # Check if drift is taking place\n",
        " if result.p_value <= alpha:\n",
        "     counter += 1\n"
      ],
      "metadata": {
        "id": "XQUkfJWvETMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero day dataset"
      ],
      "metadata": {
        "id": "SsYT57N_-XlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "counter = 0\n",
        "for i in range(X_train.shape[1]):\n",
        "        feature_idx = i\n",
        "        alpha = 0.01\n",
        "        # Define and fit detector\n",
        "        detector = KSTest()\n",
        "\n",
        "        X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        __ = detector.fit(X_train_numeric)\n",
        "            # Convert the feature column to numeric before comparing\n",
        "        X_test_numeric = pd.to_numeric(zero.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        "        # Check if drift is taking place\n",
        "        if result.p_value <= alpha:\n",
        "            counter += 1\n",
        "        if counter>(X_train.shape[1]/2):\n",
        "          print(\"More than half of features had data drift detected.\")\n",
        "\n",
        "          X_add = zero.sample(frac=0.2, random_state=42)\n",
        "          y_add = tz.sample(frac=0.2, random_state=42)\n",
        "          X_train = pd.concat([X_train, X_add])\n",
        "          y_train = pd.concat([y_train, y_add])\n",
        "          X_test = zero.drop(X_add.index)\n",
        "          y_test = tz.drop(y_add.index)\n",
        "          print(\"Datasets updated\")\n",
        "          break\n",
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "   # Reset TP, FP, FN, TN for each LR value\n",
        "   TP = 0\n",
        "   FP = 0\n",
        "   FN = 0\n",
        "   TN = 0\n",
        "\n",
        "   X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "   clf.fit(X_ss, y_ss)\n",
        "\n",
        "   # Unlabeled score\n",
        "   print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "   y_pred = clf.predict(X_test)\n",
        "   for i in range(y_test.shape[0]):\n",
        "       if y_pred[i] == 0 and tz[i] == 0:\n",
        "          TN += 1\n",
        "       elif y_pred[i] == 0 and tz[i] == 1:\n",
        "          FN += 1\n",
        "       elif y_pred[i] == 1 and tz[i] == 0:\n",
        "          FP += 1\n",
        "       elif y_pred[i] == 1 and tz[i] == 1:\n",
        "          TP += 1\n",
        "   precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "   recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "   accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "   print(f'The results for {lr} are:')\n",
        "   print(f'Precision: {precision:.5f}')\n",
        "   print(f'Recall: {recall:.5f}')\n",
        "   print(f'F1: {f1:.5f}')\n",
        "   print(f'Accuracy: {accuracy:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "cZtVSmP6JeA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece7cbaf-b32e-4752-9e22-3fca77e805f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "More than half of features had data drift detected.\n",
            "Datasets updated\n",
            "[LR=0.1] Unlabeled score: 0.9912\n",
            "The results for 0.1 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.2] Unlabeled score: 0.9975\n",
            "The results for 0.2 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.3] Unlabeled score: 0.9970\n",
            "The results for 0.3 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.4] Unlabeled score: 0.9977\n",
            "The results for 0.4 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User sample dataset"
      ],
      "metadata": {
        "id": "X2tXWSs9-Uqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "counter = 0\n",
        "for i in range(X_train.shape[1]):\n",
        "        feature_idx = i\n",
        "        alpha = 0.01\n",
        "        # Define and fit detector\n",
        "        detector = KSTest()\n",
        "\n",
        "        X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        __ = detector.fit(X_train_numeric)\n",
        "            # Convert the feature column to numeric before comparing\n",
        "        X_test_numeric = pd.to_numeric(user.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        "        # Check if drift is taking place\n",
        "        if result.p_value <= alpha:\n",
        "            counter += 1\n",
        "        if counter>(X_train.shape[1]/2):\n",
        "          print(\"More than half of features had data drift detected.\")\n",
        "\n",
        "          X_add = user.sample(frac=0.2, random_state=42)\n",
        "          y_add = tu.sample(frac=0.2, random_state=42)\n",
        "          X_train = pd.concat([X_train, X_add])\n",
        "          y_train = pd.concat([y_train, y_add])\n",
        "          X_test = user.drop(X_add.index)\n",
        "          y_test = tu.drop(y_add.index)\n",
        "          print(\"Datasets updated\")\n",
        "          break\n",
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "   # Reset TP, FP, FN, TN for each LR value\n",
        "   TP = 0\n",
        "   FP = 0\n",
        "   FN = 0\n",
        "   TN = 0\n",
        "\n",
        "   X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "   clf.fit(X_ss, y_ss)\n",
        "\n",
        "   # Unlabeled score\n",
        "   print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "   y_pred = clf.predict(X_test)\n",
        "   for i in range(y_test.shape[0]):\n",
        "       if y_pred[i] == 0 and tu[i] == 0:\n",
        "          TN += 1\n",
        "       elif y_pred[i] == 0 and tu[i] == 1:\n",
        "          FN += 1\n",
        "       elif y_pred[i] == 1 and tu[i] == 0:\n",
        "          FP += 1\n",
        "       elif y_pred[i] == 1 and tu[i] == 1:\n",
        "          TP += 1\n",
        "   precision = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
        "   recall = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "   accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "   print(f'The results for {lr} are:')\n",
        "   print(f'Precision: {precision:.5f}')\n",
        "   print(f'Recall: {recall:.5f}')\n",
        "   print(f'F1: {f1:.5f}')\n",
        "   print(f'Accuracy: {accuracy:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGfrEn4DDEQk",
        "outputId": "acba33c2-6a7e-4431-d5a7-3ad1aea23dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "More than half of features had data drift detected.\n",
            "Datasets updated\n",
            "[LR=0.1] Unlabeled score: 0.9893\n",
            "The results for 0.1 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.98669\n",
            "F1: 0.99330\n",
            "Accuracy: 0.98669\n",
            "[LR=0.2] Unlabeled score: 0.9944\n",
            "The results for 0.2 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.99968\n",
            "F1: 0.99984\n",
            "Accuracy: 0.99968\n",
            "[LR=0.3] Unlabeled score: 0.9963\n",
            "The results for 0.3 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.99946\n",
            "F1: 0.99973\n",
            "Accuracy: 0.99946\n",
            "[LR=0.4] Unlabeled score: 0.9949\n",
            "The results for 0.4 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.99978\n",
            "F1: 0.99989\n",
            "Accuracy: 0.99978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TP = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "TN = 0\n",
        "\n",
        "\n",
        "y_pred = clf.predict(user)\n",
        "\n",
        "TN, FP, FN, TP = confusion_matrix(y_pred, tu).ravel()\n",
        "\n",
        "precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "\n",
        "print(f'Precision: {precision:.5f}')\n",
        "print(f'Recall: {recall:.5f}')\n",
        "print(f'F1: {f1:.5f}')\n",
        "print(f'Accuracy: {accuracy:.5f}')\n"
      ],
      "metadata": {
        "id": "5xkeK_iJLoNB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}