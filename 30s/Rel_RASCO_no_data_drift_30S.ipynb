{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Sh8tTb3V74sOjbEBl2732j8SQhod3iXB",
      "authorship_tag": "ABX9TyNA5peZYrF+Nf7+Dv/qjuTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pvfalcao/A-semi-supervised-learning-approach-with-data-drift-detection-to-deal-with-ransomware/blob/main/30s/Rel_RASCO_no_data_drift_30S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação de bibliotecas\n"
      ],
      "metadata": {
        "id": "-gm4LuQjklVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sslearn\n",
        "!pip install frouros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXVlby4mLgBP",
        "outputId": "81cb85fb-4326-4b68-d24a-5cce03dbe97f",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sslearn in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.12/dist-packages (from sslearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.12/dist-packages (from sslearn) (2.2.2)\n",
            "Requirement already satisfied: scikit_learn>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.14.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from sslearn) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>=1.2.0->sslearn) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->sslearn) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->sslearn) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->sslearn) (1.17.0)\n",
            "Requirement already satisfied: frouros in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: matplotlib<3.10,>=3.8.2 in /usr/local/lib/python3.12/dist-packages (from frouros) (3.9.4)\n",
            "Requirement already satisfied: numpy<2.2,>=1.26.3 in /usr/local/lib/python3.12/dist-packages (from frouros) (2.0.2)\n",
            "Requirement already satisfied: requests<2.33,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from frouros) (2.32.4)\n",
            "Requirement already satisfied: scipy<1.15,>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from frouros) (1.14.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from frouros) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<3.10,>=3.8.2->frouros) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ch979MWf0McF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sslearn\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sslearn.wrapper import RelRasco\n",
        "from sslearn.model_selection import artificial_ssl_dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from frouros.callbacks.batch import PermutationTestDistanceBased\n",
        "from frouros.detectors.data_drift import MMD\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.manifold import TSNE\n",
        "from frouros.detectors.data_drift import KSTest\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recebendo conjunto de dados\n"
      ],
      "metadata": {
        "id": "2crT30H6kvMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/content/drive/MyDrive/Navarra/N30S30/N30S30.csv', header = None)\n",
        "zero = pd.read_csv(r'/content/drive/MyDrive/Navarra/N30S30/zeroDays.csv', header = None)\n",
        "user = pd.read_csv(r'/content/drive/MyDrive/Navarra/N30S30/userSamples_train.csv', header = None)\n",
        "\n",
        "targets = df.iloc[:,df.shape[1] - 1]\n",
        "df = df.iloc[:,0:-1]\n",
        "tz = zero.iloc[:,zero.shape[1] - 1]\n",
        "zero = zero.iloc[:,0:-1]\n",
        "tu = user.iloc[:,user.shape[1] - 1]\n",
        "user = user.iloc[:,0:-1]\n"
      ],
      "metadata": {
        "id": "yEYN4Nny0Uf0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo"
      ],
      "metadata": {
        "id": "-3dGzmId-b0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Initialize the variables\n",
        "\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "# Initialize 10-Fold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "clf = RelRasco()\n",
        "\n",
        "#Consumption metrics\n",
        "\n",
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "\n",
        "  psutil.cpu_percent(interval=None)\n",
        "  start = time.process_time()\n",
        "\n",
        "  # Split the dataset into 10 folds\n",
        "\n",
        "  for fold, (train_idx, test_idx) in enumerate(skf.split(df, targets)):\n",
        "\n",
        "      # Select data using .iloc to get pandas DataFrames/Series\n",
        "      train_features = df.iloc[train_idx]\n",
        "      train_labels = targets.iloc[train_idx]\n",
        "      test_features = df.iloc[test_idx]\n",
        "      test_labels = targets.iloc[test_idx]\n",
        "      TP = 0\n",
        "      FP = 0\n",
        "      TN = 0\n",
        "      FN = 0\n",
        "      precision_list = []\n",
        "      recall_list = []\n",
        "      f1_list = []\n",
        "      accuracy_list = []\n",
        "\n",
        "      X_train, X_test = df.iloc[train_idx], df.iloc[test_idx]\n",
        "      y_train, y_test = targets.iloc[train_idx], targets.iloc[test_idx]\n",
        "\n",
        "      X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "      clf.fit(X_ss, y_ss)\n",
        "\n",
        "        # Unlabeled score\n",
        "      print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "\n",
        "      y_pred = clf.predict(X_test)\n",
        "\n",
        "      TN, FP, FN, TP = confusion_matrix(y_pred, y_test).ravel()\n",
        "\n",
        "      precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "      recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "      f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "      accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "\n",
        "\n",
        "      accuracy_list.append(accuracy)\n",
        "      precision_list.append(precision)\n",
        "      recall_list.append(recall)\n",
        "      f1_list.append(f1)\n",
        "\n",
        "\n",
        "\n",
        "  #Consumption measures\n",
        "  end = time.process_time()\n",
        "  print('The processing time was:', end - start)\n",
        "  cpu_usage_system = psutil.cpu_percent(interval=None)\n",
        "  print(f\"System-wide CPU usage: {cpu_usage_system}%\")\n",
        "  print(f\"Load average:{psutil.getloadavg()}\")\n",
        "  print(f\"CPU Frequency:{psutil.cpu_freq()}\")\n",
        "  print(\"CPU usage (%):\", psutil.cpu_percent())\n",
        "  print(\"CPU usage (%):\", psutil.cpu_percent())\n",
        "  ram = psutil.virtual_memory()\n",
        "  print(\"RAM usage (%):\", ram.percent)\n",
        "  print(\"RAM used (GB):\", round(ram.used / 1e9, 2))\n",
        "  mean_precision = sum(precision_list) / len(precision_list)\n",
        "  mean_recall = sum(recall_list) / len(recall_list)\n",
        "  mean_f1 = sum(f1_list) / len(f1_list)\n",
        "  mean_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
        "  print(f'Mean precision: {mean_precision:.5f}')\n",
        "  print(f'Mean recall: {mean_recall:.5f}')\n",
        "  print(f'Mean F1 Score: {mean_f1:.5f}')\n",
        "  print(f'Mean accuracy: {mean_accuracy:.5f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-RG403E0XHh",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c721a4-05c2-4fa6-8623-2efad84d0aa7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR=0.1] Unlabeled score: 0.9930\n",
            "[LR=0.1] Unlabeled score: 0.9928\n",
            "[LR=0.1] Unlabeled score: 0.9968\n",
            "[LR=0.1] Unlabeled score: 0.9956\n",
            "[LR=0.1] Unlabeled score: 0.9952\n",
            "[LR=0.1] Unlabeled score: 0.9957\n",
            "[LR=0.1] Unlabeled score: 0.9945\n",
            "[LR=0.1] Unlabeled score: 0.9971\n",
            "[LR=0.1] Unlabeled score: 0.9928\n",
            "[LR=0.1] Unlabeled score: 0.9949\n",
            "The processing time was: 97.283097344\n",
            "System-wide CPU usage: 75.1%\n",
            "Load average:(2.14892578125, 1.5595703125, 0.794921875)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.0\n",
            "RAM used (GB): 1.57\n",
            "Mean precision: 0.98137\n",
            "Mean recall: 0.99371\n",
            "Mean F1 Score: 0.98750\n",
            "Mean accuracy: 0.99338\n",
            "[LR=0.2] Unlabeled score: 0.9972\n",
            "[LR=0.2] Unlabeled score: 0.9966\n",
            "[LR=0.2] Unlabeled score: 0.9969\n",
            "[LR=0.2] Unlabeled score: 0.9963\n",
            "[LR=0.2] Unlabeled score: 0.9969\n",
            "[LR=0.2] Unlabeled score: 0.9974\n",
            "[LR=0.2] Unlabeled score: 0.9975\n",
            "[LR=0.2] Unlabeled score: 0.9976\n",
            "[LR=0.2] Unlabeled score: 0.9966\n",
            "[LR=0.2] Unlabeled score: 0.9974\n",
            "The processing time was: 191.50154783099998\n",
            "System-wide CPU usage: 66.9%\n",
            "Load average:(1.5126953125, 1.5966796875, 0.9677734375)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 13.5\n",
            "RAM used (GB): 1.5\n",
            "Mean precision: 0.99586\n",
            "Mean recall: 0.99586\n",
            "Mean F1 Score: 0.99586\n",
            "Mean accuracy: 0.99779\n",
            "[LR=0.3] Unlabeled score: 0.9973\n",
            "[LR=0.3] Unlabeled score: 0.9977\n",
            "[LR=0.3] Unlabeled score: 0.9979\n",
            "[LR=0.3] Unlabeled score: 0.9980\n",
            "[LR=0.3] Unlabeled score: 0.9974\n",
            "[LR=0.3] Unlabeled score: 0.9975\n",
            "[LR=0.3] Unlabeled score: 0.9984\n",
            "[LR=0.3] Unlabeled score: 0.9974\n",
            "[LR=0.3] Unlabeled score: 0.9971\n",
            "[LR=0.3] Unlabeled score: 0.9975\n",
            "The processing time was: 298.205313298\n",
            "System-wide CPU usage: 66.3%\n",
            "Load average:(1.341796875, 1.46142578125, 1.08984375)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 13.5\n",
            "RAM used (GB): 1.5\n",
            "Mean precision: 0.99793\n",
            "Mean recall: 0.99587\n",
            "Mean F1 Score: 0.99690\n",
            "Mean accuracy: 0.99835\n",
            "[LR=0.4] Unlabeled score: 0.9983\n",
            "[LR=0.4] Unlabeled score: 0.9988\n",
            "[LR=0.4] Unlabeled score: 0.9985\n",
            "[LR=0.4] Unlabeled score: 0.9983\n",
            "[LR=0.4] Unlabeled score: 0.9983\n",
            "[LR=0.4] Unlabeled score: 0.9980\n",
            "[LR=0.4] Unlabeled score: 0.9976\n",
            "[LR=0.4] Unlabeled score: 0.9981\n",
            "[LR=0.4] Unlabeled score: 0.9980\n",
            "[LR=0.4] Unlabeled score: 0.9983\n",
            "The processing time was: 424.24071215699996\n",
            "System-wide CPU usage: 66.9%\n",
            "Load average:(1.53857421875, 1.4453125, 1.20654296875)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 13.7\n",
            "RAM used (GB): 1.52\n",
            "Mean precision: 0.99793\n",
            "Mean recall: 1.00000\n",
            "Mean F1 Score: 0.99896\n",
            "Mean accuracy: 0.99945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero day dataset"
      ],
      "metadata": {
        "id": "SsYT57N_-XlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "   # Reset TP, FP, FN, TN for each LR value\n",
        "   TP = 0\n",
        "   FP = 0\n",
        "   FN = 0\n",
        "   TN = 0\n",
        "\n",
        "   X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "   clf.fit(X_ss, y_ss)\n",
        "\n",
        "   # Unlabeled score\n",
        "   print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "   y_pred = clf.predict(zero)\n",
        "   for i in range(tz.shape[0]):\n",
        "       if y_pred[i] == 0 and tz[i] == 0:\n",
        "          TN += 1\n",
        "       elif y_pred[i] == 0 and tz[i] == 1:\n",
        "          FN += 1\n",
        "       elif y_pred[i] == 1 and tz[i] == 0:\n",
        "          FP += 1\n",
        "       elif y_pred[i] == 1 and tz[i] == 1:\n",
        "          TP += 1\n",
        "   precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "   recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "   accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "   print(f'The results for {lr} are:')\n",
        "   print(f'Precision: {precision:.5f}')\n",
        "   print(f'Recall: {recall:.5f}')\n",
        "   print(f'F1: {f1:.5f}')\n",
        "   print(f'Accuracy: {accuracy:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "YX_m7WVEO_H3",
        "outputId": "6fabfc3e-83ce-4887-a5ba-cc32d25ad4a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR=0.1] Unlabeled score: 0.9961\n",
            "The results for 0.1 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.2] Unlabeled score: 0.9971\n",
            "The results for 0.2 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.3] Unlabeled score: 0.9979\n",
            "The results for 0.3 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.95690\n",
            "F1: 0.97797\n",
            "Accuracy: 0.95690\n",
            "[LR=0.4] Unlabeled score: 0.9970\n",
            "The results for 0.4 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User sample dataset"
      ],
      "metadata": {
        "id": "X2tXWSs9-Uqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "   # Reset TP, FP, FN, TN for each LR value\n",
        "   TP = 0\n",
        "   FP = 0\n",
        "   FN = 0\n",
        "   TN = 0\n",
        "\n",
        "   X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "   clf.fit(X_ss, y_ss)\n",
        "\n",
        "   # Unlabeled score\n",
        "   print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "   y_pred = clf.predict(user)\n",
        "   for i in range(tu.shape[0]):\n",
        "       if y_pred[i] == 0 and tu[i] == 0:\n",
        "          TN += 1\n",
        "       elif y_pred[i] == 0 and tu[i] == 1:\n",
        "          FN += 1\n",
        "       elif y_pred[i] == 1 and tu[i] == 0:\n",
        "          FP += 1\n",
        "       elif y_pred[i] == 1 and tu[i] == 1:\n",
        "          TP += 1\n",
        "   precision = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
        "   recall = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "   accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "   print(f'The results for {lr} are:')\n",
        "   print(f'Precision: {precision:.5f}')\n",
        "   print(f'Recall: {recall:.5f}')\n",
        "   print(f'F1: {f1:.5f}')\n",
        "   print(f'Accuracy: {accuracy:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "5xkeK_iJLoNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca3e380-4eb0-4997-cfa4-13d8f3377b0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR=0.1] Unlabeled score: 0.9965\n",
            "The results for 0.1 are:\n",
            "Precision: 0.00000\n",
            "Recall: 0.00000\n",
            "F1: 0.00000\n",
            "Accuracy: 0.00000\n",
            "[LR=0.2] Unlabeled score: 0.9953\n",
            "The results for 0.2 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.04649\n",
            "F1: 0.08884\n",
            "Accuracy: 0.04649\n",
            "[LR=0.3] Unlabeled score: 0.9976\n",
            "The results for 0.3 are:\n",
            "Precision: 0.00000\n",
            "Recall: 0.00000\n",
            "F1: 0.00000\n",
            "Accuracy: 0.00000\n",
            "[LR=0.4] Unlabeled score: 0.9976\n",
            "The results for 0.4 are:\n",
            "Precision: 0.00000\n",
            "Recall: 0.00000\n",
            "F1: 0.00000\n",
            "Accuracy: 0.00000\n"
          ]
        }
      ]
    }
  ]
}