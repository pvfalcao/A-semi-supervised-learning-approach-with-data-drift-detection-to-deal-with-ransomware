{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12Ok9wvdI7xvaXeSv3yEz1oQ1HSAyPvLF",
      "authorship_tag": "ABX9TyOzOdYhvbPogZC97EV4jTjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pvfalcao/A-semi-supervised-learning-approach-with-data-drift-detection-to-deal-with-ransomware/blob/main/20s/Rel_RASCO_with_data_drift_20S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação de bibliotecas\n"
      ],
      "metadata": {
        "id": "-gm4LuQjklVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sslearn\n",
        "!pip install frouros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MXVlby4mLgBP",
        "outputId": "192e1482-9adf-40a5-9a54-1cbdcbee72a0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sslearn\n",
            "  Downloading sslearn-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.12/dist-packages (from sslearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.12/dist-packages (from sslearn) (2.2.2)\n",
            "Requirement already satisfied: scikit_learn>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from sslearn) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from sslearn) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.3->sslearn) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>=1.2.0->sslearn) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->sslearn) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->sslearn) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->sslearn) (1.17.0)\n",
            "Downloading sslearn-1.1.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sslearn\n",
            "Successfully installed sslearn-1.1.0\n",
            "Collecting frouros\n",
            "  Downloading frouros-0.9.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting matplotlib<3.10,>=3.8.2 (from frouros)\n",
            "  Downloading matplotlib-3.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.2,>=1.26.3 in /usr/local/lib/python3.12/dist-packages (from frouros) (2.0.2)\n",
            "Requirement already satisfied: requests<2.33,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from frouros) (2.32.4)\n",
            "Collecting scipy<1.15,>=1.12.0 (from frouros)\n",
            "  Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from frouros) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.10,>=3.8.2->frouros) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<2.33,>=2.31.0->frouros) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<3.10,>=3.8.2->frouros) (1.17.0)\n",
            "Downloading frouros-0.9.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, matplotlib, frouros\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "Successfully installed frouros-0.9.0 matplotlib-3.9.4 scipy-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "cd2054d7157b42f8a4c8c447fe340629"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch979MWf0McF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sslearn\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sslearn.wrapper import RelRasco\n",
        "from sslearn.model_selection import artificial_ssl_dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from frouros.callbacks.batch import PermutationTestDistanceBased\n",
        "from frouros.detectors.data_drift import MMD\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.manifold import TSNE\n",
        "from frouros.detectors.data_drift import KSTest\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recebendo conjunto de dados\n"
      ],
      "metadata": {
        "id": "2crT30H6kvMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/content/drive/MyDrive/Navarra/N20S20/N20S20.csv', header = None)\n",
        "zero = pd.read_csv(r'/content/drive/MyDrive/Navarra/N20S20/zeroDays.csv', header = None)\n",
        "user = pd.read_csv(r'/content/drive/MyDrive/Navarra/N20S20/userSamples_train.csv', header = None)\n",
        "\n",
        "targets = df.iloc[:,df.shape[1] - 1]\n",
        "df = df.iloc[:,0:-1]\n",
        "tz = zero.iloc[:,zero.shape[1] - 1]\n",
        "zero = zero.iloc[:,0:-1]\n",
        "tu = user.iloc[:,user.shape[1] - 1]\n",
        "user = user.iloc[:,0:-1]\n"
      ],
      "metadata": {
        "id": "yEYN4Nny0Uf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf-QtKbZ_8t1",
        "outputId": "091cfad3-1e96-4e86-d63f-3e0f8b003653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo"
      ],
      "metadata": {
        "id": "-3dGzmId-b0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Initialize the variables\n",
        "\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "# Initialize 10-Fold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "clf = RelRasco()\n",
        "\n",
        "#Consumption metrics\n",
        "\n",
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "\n",
        "  psutil.cpu_percent(interval=None)\n",
        "  start = time.process_time()\n",
        "\n",
        "  # Split the dataset into 10 folds\n",
        "\n",
        "  for fold, (train_idx, test_idx) in enumerate(skf.split(df, targets)):\n",
        "\n",
        "      # Select data using .iloc to get pandas DataFrames/Series\n",
        "      train_features = df.iloc[train_idx]\n",
        "      train_labels = targets.iloc[train_idx]\n",
        "      test_features = df.iloc[test_idx]\n",
        "      test_labels = targets.iloc[test_idx]\n",
        "      TP = 0\n",
        "      FP = 0\n",
        "      TN = 0\n",
        "      FN = 0\n",
        "      counter = 0\n",
        "      precision_list = []\n",
        "      recall_list = []\n",
        "      f1_list = []\n",
        "      accuracy_list = []\n",
        "\n",
        "\n",
        "      X_train, X_test = df.iloc[train_idx], df.iloc[test_idx]\n",
        "      y_train, y_test = targets.iloc[train_idx], targets.iloc[test_idx]\n",
        "\n",
        "      for i in range(X_train.shape[1]):\n",
        "        feature_idx = i\n",
        "        alpha = 0.01\n",
        "        # Define and fit detector\n",
        "        detector = KSTest()\n",
        "\n",
        "        X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        __ = detector.fit(X_train_numeric)\n",
        "            # Convert the feature column to numeric before comparing\n",
        "        X_test_numeric = pd.to_numeric(X_test.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        "        # Check if drift is taking place\n",
        "        if result.p_value <= alpha:\n",
        "            counter += 1\n",
        "        if counter>(X_train.shape[1]/2):\n",
        "          print(\"More than half of features had data drift detected.\")\n",
        "\n",
        "          X_add = X_test.sample(frac=0.2, random_state=42)\n",
        "          y_add = y_test.sample(frac=0.2, random_state=42)\n",
        "          X_train = pd.concat([X_train, X_add])\n",
        "          y_train = pd.concat([y_train, y_add])\n",
        "          X_test = X_test.drop(X_add.index)\n",
        "          y_test = y_test.drop(y_add.index)\n",
        "          print(\"Datasets updated\")\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "      X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "      clf.fit(X_ss, y_ss)\n",
        "\n",
        "        # Unlabeled score\n",
        "      print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      y_pred = clf.predict(X_test)\n",
        "\n",
        "      TN, FP, FN, TP = confusion_matrix(y_pred, y_test).ravel()\n",
        "\n",
        "      precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "      recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "      f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "      accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "\n",
        "\n",
        "      accuracy_list.append(accuracy)\n",
        "      precision_list.append(precision)\n",
        "      recall_list.append(recall)\n",
        "      f1_list.append(f1)\n",
        "\n",
        "\n",
        "\n",
        "  #Consumption measures\n",
        "  end = time.process_time()\n",
        "  print('The processing time was:', end - start)\n",
        "  cpu_usage_system = psutil.cpu_percent(interval=None)\n",
        "  print(f\"System-wide CPU usage: {cpu_usage_system}%\")\n",
        "  print(f\"Load average:{psutil.getloadavg()}\")\n",
        "  print(f\"CPU Frequency:{psutil.cpu_freq()}\")\n",
        "  print(\"CPU usage (%):\", psutil.cpu_percent())\n",
        "  print(\"CPU usage (%):\", psutil.cpu_percent())\n",
        "  ram = psutil.virtual_memory()\n",
        "  print(\"RAM usage (%):\", ram.percent)\n",
        "  print(\"RAM used (GB):\", round(ram.used / 1e9, 2))\n",
        "  mean_precision = sum(precision_list) / len(precision_list)\n",
        "  mean_recall = sum(recall_list) / len(recall_list)\n",
        "  mean_f1 = sum(f1_list) / len(f1_list)\n",
        "  mean_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
        "  print(f'Mean precision: {mean_precision:.5f}')\n",
        "  print(f'Mean recall: {mean_recall:.5f}')\n",
        "  print(f'Mean F1 Score: {mean_f1:.5f}')\n",
        "  print(f'Mean accuracy: {mean_accuracy:.5f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-RG403E0XHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cac7f9-5c91-4af6-d860-eb049f6aade3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR=0.1] Unlabeled score: 0.9965\n",
            "[LR=0.1] Unlabeled score: 0.9958\n",
            "[LR=0.1] Unlabeled score: 0.9959\n",
            "[LR=0.1] Unlabeled score: 0.9925\n",
            "[LR=0.1] Unlabeled score: 0.9958\n",
            "[LR=0.1] Unlabeled score: 0.9932\n",
            "[LR=0.1] Unlabeled score: 0.9967\n",
            "[LR=0.1] Unlabeled score: 0.9966\n",
            "[LR=0.1] Unlabeled score: 0.9941\n",
            "[LR=0.1] Unlabeled score: 0.9949\n",
            "The processing time was: 104.988408375\n",
            "System-wide CPU usage: 66.6%\n",
            "Load average:(1.466796875, 1.4453125, 0.91357421875)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.4\n",
            "RAM used (GB): 1.62\n",
            "Mean precision: 0.99447\n",
            "Mean recall: 0.98900\n",
            "Mean F1 Score: 0.99172\n",
            "Mean accuracy: 0.99493\n",
            "[LR=0.2] Unlabeled score: 0.9968\n",
            "[LR=0.2] Unlabeled score: 0.9970\n",
            "[LR=0.2] Unlabeled score: 0.9977\n",
            "[LR=0.2] Unlabeled score: 0.9958\n",
            "[LR=0.2] Unlabeled score: 0.9965\n",
            "[LR=0.2] Unlabeled score: 0.9971\n",
            "[LR=0.2] Unlabeled score: 0.9957\n",
            "[LR=0.2] Unlabeled score: 0.9979\n",
            "[LR=0.2] Unlabeled score: 0.9971\n",
            "[LR=0.2] Unlabeled score: 0.9977\n",
            "The processing time was: 208.68621628000005\n",
            "System-wide CPU usage: 67.0%\n",
            "Load average:(1.49951171875, 1.47021484375, 1.03369140625)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.6\n",
            "RAM used (GB): 1.65\n",
            "Mean precision: 0.99447\n",
            "Mean recall: 0.99447\n",
            "Mean F1 Score: 0.99447\n",
            "Mean accuracy: 0.99662\n",
            "[LR=0.3] Unlabeled score: 0.9980\n",
            "[LR=0.3] Unlabeled score: 0.9978\n",
            "[LR=0.3] Unlabeled score: 0.9981\n",
            "[LR=0.3] Unlabeled score: 0.9966\n",
            "[LR=0.3] Unlabeled score: 0.9977\n",
            "[LR=0.3] Unlabeled score: 0.9979\n",
            "[LR=0.3] Unlabeled score: 0.9976\n",
            "[LR=0.3] Unlabeled score: 0.9975\n",
            "[LR=0.3] Unlabeled score: 0.9963\n",
            "[LR=0.3] Unlabeled score: 0.9973\n",
            "The processing time was: 341.76253511100003\n",
            "System-wide CPU usage: 67.9%\n",
            "Load average:(1.46923828125, 1.50048828125, 1.18505859375)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.5\n",
            "RAM used (GB): 1.64\n",
            "Mean precision: 0.99585\n",
            "Mean recall: 0.99310\n",
            "Mean F1 Score: 0.99448\n",
            "Mean accuracy: 0.99662\n",
            "[LR=0.4] Unlabeled score: 0.9978\n",
            "[LR=0.4] Unlabeled score: 0.9975\n",
            "[LR=0.4] Unlabeled score: 0.9979\n",
            "[LR=0.4] Unlabeled score: 0.9977\n",
            "[LR=0.4] Unlabeled score: 0.9976\n",
            "[LR=0.4] Unlabeled score: 0.9970\n",
            "[LR=0.4] Unlabeled score: 0.9975\n",
            "[LR=0.4] Unlabeled score: 0.9973\n",
            "[LR=0.4] Unlabeled score: 0.9980\n",
            "[LR=0.4] Unlabeled score: 0.9978\n",
            "The processing time was: 483.4527100029999\n",
            "System-wide CPU usage: 66.8%\n",
            "Load average:(1.40087890625, 1.61962890625, 1.3896484375)\n",
            "CPU Frequency:scpufreq(current=2199.998, min=0.0, max=0.0)\n",
            "CPU usage (%): 0.0\n",
            "CPU usage (%): 0.0\n",
            "RAM usage (%): 14.4\n",
            "RAM used (GB): 1.62\n",
            "Mean precision: 0.99862\n",
            "Mean recall: 0.99449\n",
            "Mean F1 Score: 0.99655\n",
            "Mean accuracy: 0.99789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(X_train.shape[1]):\n",
        " feature_idx = i\n",
        " alpha = 0.01\n",
        " # Define and fit detector\n",
        " detector = KSTest()\n",
        "\n",
        " X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        " __ = detector.fit(X_train_numeric)\n",
        "    # Convert the feature column to numeric before comparing\n",
        " X_test_numeric = pd.to_numeric(X_test.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        " result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        " # Check if drift is taking place\n",
        " if result.p_value <= alpha:\n",
        "     counter += 1\n"
      ],
      "metadata": {
        "id": "XQUkfJWvETMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero day dataset"
      ],
      "metadata": {
        "id": "SsYT57N_-XlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "counter = 0\n",
        "for i in range(X_train.shape[1]):\n",
        "        feature_idx = i\n",
        "        alpha = 0.01\n",
        "        # Define and fit detector\n",
        "        detector = KSTest()\n",
        "\n",
        "        X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        __ = detector.fit(X_train_numeric)\n",
        "            # Convert the feature column to numeric before comparing\n",
        "        X_test_numeric = pd.to_numeric(zero.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        "        # Check if drift is taking place\n",
        "        if result.p_value <= alpha:\n",
        "            counter += 1\n",
        "        if counter>(X_train.shape[1]/2):\n",
        "          print(\"More than half of features had data drift detected.\")\n",
        "\n",
        "          X_add = zero.sample(frac=0.2, random_state=42)\n",
        "          y_add = tz.sample(frac=0.2, random_state=42)\n",
        "          X_train = pd.concat([X_train, X_add])\n",
        "          y_train = pd.concat([y_train, y_add])\n",
        "          X_test = zero.drop(X_add.index)\n",
        "          y_test = tz.drop(y_add.index)\n",
        "          print(\"Datasets updated\")\n",
        "          break\n",
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "   # Reset TP, FP, FN, TN for each LR value\n",
        "   TP = 0\n",
        "   FP = 0\n",
        "   FN = 0\n",
        "   TN = 0\n",
        "\n",
        "   X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "   clf.fit(X_ss, y_ss)\n",
        "\n",
        "   # Unlabeled score\n",
        "   print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "   y_pred = clf.predict(X_test)\n",
        "   for i in range(y_test.shape[0]):\n",
        "       if y_pred[i] == 0 and tz[i] == 0:\n",
        "          TN += 1\n",
        "       elif y_pred[i] == 0 and tz[i] == 1:\n",
        "          FN += 1\n",
        "       elif y_pred[i] == 1 and tz[i] == 0:\n",
        "          FP += 1\n",
        "       elif y_pred[i] == 1 and tz[i] == 1:\n",
        "          TP += 1\n",
        "   precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "   recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "   accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "   print(f'The results for {lr} are:')\n",
        "   print(f'Precision: {precision:.5f}')\n",
        "   print(f'Recall: {recall:.5f}')\n",
        "   print(f'F1: {f1:.5f}')\n",
        "   print(f'Accuracy: {accuracy:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "cZtVSmP6JeA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21a36f8-afc3-4801-b29d-3a8107a31c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "More than half of features had data drift detected.\n",
            "Datasets updated\n",
            "[LR=0.1] Unlabeled score: 0.9957\n",
            "The results for 0.1 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.2] Unlabeled score: 0.9970\n",
            "The results for 0.2 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.3] Unlabeled score: 0.9971\n",
            "The results for 0.3 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n",
            "[LR=0.4] Unlabeled score: 0.9974\n",
            "The results for 0.4 are:\n",
            "Precision: 1.00000\n",
            "Recall: 1.00000\n",
            "F1: 1.00000\n",
            "Accuracy: 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User sample dataset"
      ],
      "metadata": {
        "id": "X2tXWSs9-Uqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "counter = 0\n",
        "for i in range(X_train.shape[1]):\n",
        "        feature_idx = i\n",
        "        alpha = 0.01\n",
        "        # Define and fit detector\n",
        "        detector = KSTest()\n",
        "\n",
        "        X_train_numeric = pd.to_numeric(X_train.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        __ = detector.fit(X_train_numeric)\n",
        "            # Convert the feature column to numeric before comparing\n",
        "        X_test_numeric = pd.to_numeric(user.iloc[:, feature_idx], errors='coerce').to_numpy().reshape(-1, 1)\n",
        "        result, _ = detector.compare(X_test_numeric)\n",
        "\n",
        "        # Check if drift is taking place\n",
        "        if result.p_value <= alpha:\n",
        "            counter += 1\n",
        "        if counter>(X_train.shape[1]/2):\n",
        "          print(\"More than half of features had data drift detected.\")\n",
        "\n",
        "          X_add = user.sample(frac=0.2, random_state=42)\n",
        "          y_add = tu.sample(frac=0.2, random_state=42)\n",
        "          X_train = pd.concat([X_train, X_add])\n",
        "          y_train = pd.concat([y_train, y_add])\n",
        "          X_test = user.drop(X_add.index)\n",
        "          y_test = tu.drop(y_add.index)\n",
        "          print(\"Datasets updated\")\n",
        "          break\n",
        "for lr in [0.1, 0.2, 0.3, 0.4]:\n",
        "   # Reset TP, FP, FN, TN for each LR value\n",
        "   TP = 0\n",
        "   FP = 0\n",
        "   FN = 0\n",
        "   TN = 0\n",
        "\n",
        "   X_ss, y_ss, X_unl, y_unl = artificial_ssl_dataset(X_train, y_train, lr)\n",
        "   clf.fit(X_ss, y_ss)\n",
        "\n",
        "   # Unlabeled score\n",
        "   print(f\"[LR={lr}] Unlabeled score: {clf.score(X_unl, y_unl):.4f}\")\n",
        "   y_pred = clf.predict(X_test)\n",
        "   for i in range(y_test.shape[0]):\n",
        "       if y_pred[i] == 0 and tu[i] == 0:\n",
        "          TN += 1\n",
        "       elif y_pred[i] == 0 and tu[i] == 1:\n",
        "          FN += 1\n",
        "       elif y_pred[i] == 1 and tu[i] == 0:\n",
        "          FP += 1\n",
        "       elif y_pred[i] == 1 and tu[i] == 1:\n",
        "          TP += 1\n",
        "   precision = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
        "   recall = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "   f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "   accuracy = (TN + TP)/(TP + FP + FN + TN)\n",
        "   print(f'The results for {lr} are:')\n",
        "   print(f'Precision: {precision:.5f}')\n",
        "   print(f'Recall: {recall:.5f}')\n",
        "   print(f'F1: {f1:.5f}')\n",
        "   print(f'Accuracy: {accuracy:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGfrEn4DDEQk",
        "outputId": "d53687ca-b109-46a9-972e-69803e087b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "More than half of features had data drift detected.\n",
            "Datasets updated\n",
            "[LR=0.1] Unlabeled score: 0.9942\n",
            "The results for 0.1 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.99970\n",
            "F1: 0.99985\n",
            "Accuracy: 0.99970\n",
            "[LR=0.2] Unlabeled score: 0.9966\n",
            "The results for 0.2 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.99939\n",
            "F1: 0.99970\n",
            "Accuracy: 0.99939\n",
            "[LR=0.3] Unlabeled score: 0.9968\n",
            "The results for 0.3 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.99909\n",
            "F1: 0.99954\n",
            "Accuracy: 0.99909\n",
            "[LR=0.4] Unlabeled score: 0.9972\n",
            "The results for 0.4 are:\n",
            "Precision: 1.00000\n",
            "Recall: 0.99932\n",
            "F1: 0.99966\n",
            "Accuracy: 0.99932\n"
          ]
        }
      ]
    }
  ]
}